<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn How To Code An Object Oriented Neural Network In JavaScript">
    <meta name="author" content="Oppikone">

    <title>Object Oriented Neural Network In JavaScript</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div style="display:none" class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="http://www.oppikone.fi">Oppikone</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div  class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul style display="none" class="nav navbar-nav navbar-right">
                    <li>
                        <a href="http://www.oppikone.fi">Oppikone</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('http://www.oppikone.fi/templates/oppikone/files/nature/world-footer.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>Object Oriented Neural Network In JavaScript</h1>
                        <h2 class="subheading">Learn How To Code An Object Oriented Neural Network In JavaScript</h2>
                        <span class="meta">Posted by <a href="#">Heikki Kupiainen/Oppikone</a> on 2016-11-25</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
          		<h3>Neural Networks, Cars and OOP</h3><p/>

In my <a href="http://www.oppikone.fi/blog/javascript-oop.html">previous post</a> I introduced some easy techniques that enable you to program with JavaScript in an object oriented manner.
I used some examples with imaginary cars to demonstrate inheritance. However, it would be great to have examples that already have practical value as such.<p/>
Therefore I'll try to demonstrate JavaScript OOP (object oriented programming) with some more useful examples than just cars. I am going to implement 
a neural network. But first of all, just what is a neural network?<p/>

<h3>Neural Network - What Is It Good For?</h3><p/>

"Neural Network" is a very brutally abused term. It makes people think of all kinds of crazy sci-fi movie fantasies.
In reality, a neural network is just a set of some useful algorithms. Let's say that you have a table in an SQL database
that contains rows of customer data. What is their turnover, how many employees, how much profit they made and so on and did they
buy your product or not. There is probably some kind of correlation between all attributes and if they bought the product.
You feed the database table into a neural network and it will learn that correlation.
<p/>
Next time, you have some new companies on your list and you are worrying which ones might be potential customers. Well,
you just feed the data you have about them into the neural network and it will - based on previous examples - tell
which ones probably would buy the product. This information will save from quite many fruitless phone calls!
 
<h3>Creating Neuron And Neural Net</h3><p/>

Sounds great! Now, let's get down to business. I will try to create a simple neural network in JavaScript. Needless
to say, there are many neural network implementations in many programming languages and there are many online services
providing neural network functionality. But if you really want to understand how something works you must create one
by yourself.<p/>

Animal and human brains consist of billions of neurons that are somehow interconnected and somehow enable those animal
and human brains to think.<p/>

<img style="width:100%;max-width:300px" src="https://upload.wikimedia.org/wikipedia/commons/1/15/PurkinjeCell.jpg"/><p/>

So that's why I guess that we need to start by coding a neuron:

<p>

<b>var</b> Neuron = {};<p/>

That's the neuron class. Now I'll add a constructor method so we can get many instances of neurons. I guess, to create 
a clever thing we need to have tons of neurons.<p/>

Neuron.<b>new</b> = function() {<br/>
&nbsp;&nbsp;&nbsp; //let's figure out later what a neuron contains<br/>
&nbsp;&nbsp;&nbsp;<b>return</b> {};<br/>
}</br>

<p>And to have a really cluster of neurons we need a neural network to contain all neurons:</p>

<b>var</b> NeuralNet = {};<p/>

<p>A very basic neural network known as multilayer perceptron typically has a layer of input neurons, hidden neurons and output neurons.
Let's add a constructor that takes those values as parameters:

<p>
NeuralNet.new = <b>function</b>(inputNeuronCount,hiddenNeuronCount,outputNeuronCount) { <br/>
&nbsp;&nbsp;&nbsp;<b>return</b> {<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputNeuronCount: inputNeuronCount,<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hiddenNeuronCount: hiddenNeuronCount,<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputNeuronCount: outputNeuronCount<br/>
&nbsp;&nbsp;&nbsp;}<br/>
};</p>

The parameters passed above instruct the neural network on configuration of its layers. A multilayer perceptron (MLP)
often only contains really three layers of neurons. It is possible to have many hidden
layers but it depends on the case. Adding many hidden layers does not automatically make a network "more clever". Therefore, "multilayer" perceptron might be initially disappointing to those 
who wish to see a software equivalent to brain neurons: brain neurons appear to form endlessly deep networks. A "multilayer"
neuron that only can afford three layers hardly resembles the construction of thousands or billions of layers that can be found in 
a biological neural network.<p/>

But no need to be discouraged! Despite of their hollowness, multilayer perceptrons are apparently still very useful for machine learning 
purpose. They can be used as building blocks for truly deep networks. It just does not happen by adding more hidden layers but
rather chaining them up into recurrent networks instead. With MLP, you can have one or two hidden layers, depending on the case. But adding more 
than that won't make the network any better. My understanding is that neural network models better suited for recurrency than MLP are at least Hopfield, Elman and bi-directional RNN.
But MLP is a good workhorse for many classification tasks and a robust launchpad for seeking deeper wisdom!<p/>

<h3>Creating Layers</h3><p/>

<p>NeuralNet class serves as a container for layers that are created when the neural net is instantiated. Let us create constructors 
for layers. We create first a super class NeuronLayer that will contain the common features of a neuron layer. Then we create
input, output and hidden layers that extend the base class.<p/>

<textarea style="width:100%;height:400px" >
      
       var NeuronLayer = {
		new: function(neuronCount) {
			return {
				neuronCount: neuronCount
			}
		}
	};
	
       var InputLayer = {
		new: function(neuronCount) {
			return extend(NeuronLayer.new(neuronCount),{});
		}
       };
	
       var HiddenLayer = {
		new: function(neuronCount) {
			return extend(NeuronLayer.new(neuronCount),{});
		}
       };

       var OutputLayer = {
		new: function(neuronCount) {
			return extend(NeuronLayer.new(neuronCount),{});
		}
       };
</textarea>
<p/>
Now the classes for layers have been introduced. Please check my <a href="http://www.oppikone.fi/blog/javascript-oop.html">previous post</a> for <b>extend</b> function. 
The next step is to modify NeuralNet's constructor to initialize the layers:
<p/>
<textarea style="width:100%;height:300px" >
	NeuralNet.new = function (inputNeuronCount,hiddenNeuronCount,outputNeuronCount) { 
		return  {
			inputLayer: InputLayer.new(inputNeuronCount),
			hiddenLayer: HiddenLayer.new(hiddenNeuronCount),
			outputLayer: OutputLayer.new(outputLayerCount)
		};
	};
</textarea>

<p>In case the neural network needs to have more than one hidden layer it is useful to modify the constructor to allow multiple hidden layers:</p>

<textarea style="width:100%;height:500px" >
	NeuralNet.new = function (inputNeuronCount,outputNeuronCount,hiddenLayerNeuronCounts) { 
		var neuralNet  {
			inputLayer: InputLayer.new(inputNeuronCount),
			hiddenLayers: [],
			outputLayer: OutputLayer.new(outputLayerCount)
		};

		for (var i = 0; i < hiddenLayerNeuronCounts.length; i++) {
			var hiddenLayerNeuronCount = hiddenLayerNeuronCounts[i];
			neuralNet.hiddenLayers.push(HiddenLayer.new(hiddenLayerNeuronCount));
		}
		return neuralNet;
	};
</textarea>
<p/>
Since JavaScript is a weakly typed language you don't need (and you can't) define data types in parameters. Therefore it is
recommendable for clarity to name variables in a way that suggests their data type. For instance, "outputNeuron<b>Count</b>" intuitively
indicates an integer value and "hiddenLayerNeuron<b>Counts</b>" refers to an array of integers. In my opinion!<p/>

Using the constructor I described above, let's create a neural net with two input neurons, one output neuron and one hidden layer with four neurons:<p/>

<b>var neuralNet = NeuralNet.new(2,1,[4]);</b><p/>

For comparison, if we wanted a neural net with two input neurons, one output neuron, one hidden layer with four neurons and
one hidden layer with three neurons, we would code:<p/>

<b>var neuralNet = NeuralNet.new(2,1,[4,3]);</b><p/>

Now it's time to have a new iteration of neuron layers. Each layer contains an array of neurons. We'll modify NeuronLayer
to initialize its neurons instead of jus holding a dummy number to tell the total number of neurons.<p/>

<textarea style="width:100%;height:400px" >
      
       var NeuronLayer = {
		new: function(neuronCount) {
			var neuronLayer = {
				neurons: []
			};
			for ( var i = 0; i < neuronCount; i++) {
				var neuron = Neuron.new();
				neuronLayer.neurons.push(neuron);
			}
			return neuronLayer;	
		}
	};
</textarea>

<h3>Training Data</h3><p/>

Neural network's purpose is to learn a certain dataset. The dataset is basically a table of numbers. Each column of the 
table represents a certain property and each row represents a possible value combination for those properties. This
goes well for all datasets that already have continuous values. In case of discrete values (such as categories) the 
case is more tricky because then the categories must be normalized which will then cause a lot more columns. But 
it works, anyway.  A neural network consisting of multilayer percetrons is useful in classifying tasks. For instance, you can teach
the network labeled examples of different species of flowers. Then you can let the trained network use its "wisdom"
and label some new unlabeled flower data. A classical example of this is the Iris dataset that contains variations of Iris
-flower subspecies pedal lengths.<p/>

The simplest and probably most common example training data sample, however, is XOR operator. XOR operator data is already
in normalized form (1's and 0's) and its training data is easy to generate. XOR operator takes two parameters and returns true
if they differ from each other and false if they are same. The task is to teach the neural network to understand the
logic of a XOR operator. Let's create training data for XOR operator:<p/>

<textarea style="width:100%;height:500px" >
	var XORTrainData = {
		getRandomZeroOrOne: function() {
			return parseInt(Math.random() + 0.5);
		},
				
		generate: function() {	
			var matrix = [];
			for (var i = 0; i < 100; i++) {
				var param1 = this.getRandomZeroOrOne();
				var param2 = this.getRandomZeroOrOne();
				var result = (param1 === param2) ? 0 : 1; // XOR OPERATOR!!!
				matrix.push([[param1,param2],[result]]);
			}
			return matrix;
		}
		
	}
</textarea>
<p/>

Each entry of our training data is an array containing two more arrays. First array contains a sample set of parameters 7
and the second array contains an observed result of that parameter combinations. Now, we get our training data for XOR operator:<p/>

<b>var</b> trainingData = XORTrainData.generate();<p/>

<h3>Training Procedure</h3><p/>

When training a neural network with train data, the data matrix is being fed into the neural network row by row. On each iteration,
the error margin decreases. Training is ready when the error is smaller than a threshold value. Training can also be
stopped until a desired number of iterations is reached. This means that two barrier values must be set before the 
training starts: maximum number of iterations and error threshold value. For example:<p/>

<textarea style="width:100%;height:500px">
	var trainData = XORTrainData.generate();
	
	var inputNeuronCount = 2;
	var outputNeuronCount = 1;
	var hiddenLayerCounts = [4];
	
	var network = NeuralNet.new(
			inputNeuronCount,
			outputNeuronCount,
			hiddenLayerCounts);
	
	var maxIterationsCount = 100;
	var errorThresholdValue = 0.01;	
	network.train(trainData, maxIterationsCount,errorThresholdValue);
</textarea>

<p>This procedure can be compared with a blind man with a golf club whom you want to teach hitting the hole. Every time you shout
"fire!" the blind fellow launches. You check by how wide margin he misses the hole and then you tell him something like "adjust left 2 meters". 
The blind fellow then launches again. You repeat this procedure until the ball hits the hole (threshold value reached) or you just run out of golf balls (maximum number of iterations reached).</p>

<img src="http://www.blindgolf.co.uk/uploads/images/Jim%20Hole%20in%20one.jpg" style="width:100%;max-width:350px"/><p/>

Given that the blind man is a neural network (actually, he is!) and his brain cells are neurons (in deed, they are!) then let <b>NeuralNet.train()</b> be the function to 
to teach him to hit the hole. Training consists of many repetitions until the targeted skill level is reached (threshold) or the
resources reserved for training are used up without reaching the objective (max iterations). Basically
almost any training has one thing in common. It is a procedure of exhaustive iterations. Think about teaching 
a dog to do a trick, a ski jumper pursuing a new record, just anything. Training a neural network can be modeled
in JavaScript program code similarly:<p/> 

<textarea style="width:100%;height:800px">

NeuralNet.train = function(trainData,maxIterationsCount,errorThresholdValue) {	
	
	
	var currentIterationCount = 0;
	var currentErrorMargin = 1.0;

	while (currentErrorMargin > errorThresholdValue)
		
		// stop when enough is enough
		if (currentIterationCount === maxIterationCount) {
			break;
		}	
		// stop when there is no entries left in the train data
		if (trainData.length === 0) {
		 	break;
		}
		//we take the next example from the traindata stack.
		var pattern = trainData.shift();
		var inputs = pattern[0];
	        var outputs = pattern[1];
		currentErrorMargin = this.iterate(inputs,outputs);
		currentIterationCount++;
	}
}

</textarea><p/>

Notice that I declared Neural network's train function as a <i>static method</i>. Is it a bad practice for object oriented 
programming? <b>Absolutely no</b>, if you know that your application is only going to handle one neural network at time!
And <b>absolutely yes</b>, if your application must handle many neural networks simultaneously. For simplicity,
we are using static methods here. We only need one neural network at any given time.<p/>


This is all very simple so far. But miracles start to unravel when we dive in to explore what happens inside all those countless iterations of learning.
Warning, this is going to be very complicated, almost rocket science:
<p>

<textarea style="width:100%;height:200px">
NeuralNet.iterate = function(inputs,outputs) {	
	//blind man launches the golf ball
	this.fire(inputs);
	// you check the result and tell him to adjust
	return this.adjust(outputs);
}
</textarea><p/>

Just kidding with rocket science! Each iteration really consists of these very primitive steps. To understand the next part, however,
it's important to understand first the nature of a neuron.

<h3>Neuron Is Like A Raindrop</h3><p/>

When you were little, did you ever observe how raindrops behave on a window glass when it is raining? I believe you did. You stared at a window glass and saw how a raindrop would
stay in one place, growing a little bit every time another raindrop flowed down and joined it. And when the raindrop was big enough,
it would suddenly divide in two! One part remained where it was while the other part rapidly sprinted downward until it joined another raindrop further below. 
That's exactly how neurons are! Nature repeats itself everywhere. The same neural pattern can be observed in every place. When you fill a coffee cup
and it spills over when it's full, that has something in common with a neuron!<p/>

<img src="https://upload.wikimedia.org/wikipedia/commons/7/71/GGB_reflection_in_raindrops.jpg" style="width:100%;max-width:350px"/><p/>

<i>Neuron is a container that absorbs many stimuli and fires one big stimulus when it's full.</i><p/>

My description of a neuron, as you may have noticed, is not very mathematical. It almost sounds too easy, right? But many
things we see around us that can be easily understood, for instance raindrops on window, would require extremely complicated mathematical equations to be described formally. 
Luckily, it works also the other way round: when you look at some mathematical equations you may easily think that is something hopelessly beyond your intellectual reach. 
But in reality, this is often the case only because mathematical equations are not very intuitive for human mind. I suspect that if some very complex equations and algorithms
were described in an object oriented way that is more natural to humans, they would suddenly 
become children's play for the masses.<p/>

Pragmatical programmers who are familiar with object oriented programming have always known it. Almost any overly complex
looking formal equation can become relatively easily accessible when converted into object oriented programming code.
While OOP might not be yet as intuitive as playing with Legos, it is still a great way to model
complex real world interactions in a manner that will help create computer applications to handle them.<p/>

<h3>Grids Aren't Natural But Trees Are</h3><p/>

There are many tutorials about implementing a neural network in any given computer language. Often they start nicely
by showing some charts that describe neurons having many inputs and one output, explaining how stimuli enter a neuron
through synapses and how the weights are calculated, summed and fed into the activation function. However, those tutorials
then degrade - after a neat object friendly start - into explaining how you need matrix calculations to sum up the weights
of each neuron layer. Mathematically, it is perfect. Matrix calculation isn't that difficult to understand either. And it probably
is the computationally fastest way to update neuron weights. But it is not an object oriented way to model neural interaction.
If you were to observe neurons through a microscope, you wouldn't see any matrices or tables or grids where neurons are placed by an invisible hand
like pralines in a christmas calendar. You would rather see a tree-like structure. Neurons connect to each other in a fashion that
resembles trees.<p/>

<img src="https://upload.wikimedia.org/wikipedia/en/thumb/c/c3/Tree_of_life_1500px_coloured.png/800px-Tree_of_life_1500px_coloured.png" style="width:100%;max-width:350px"/><p/>

Tree-like structures are natural. They are everywhere. In river deltas, in blood vessels, under the ground where plants form their Internet of roots, on
the roads where highways split into smaller roads, in software code where high level functions split into ever smaller instructions finally reaching the physical level of magnetic zeros and ones.  
Therefore, I will try to implement a different neural network. A neural network that is a bit more object 
oriented. I will try take a more recursive, tree-like approach instead of the typical matrix approach. Something that is a little bit more faithful to what we see in a microscope.
This is going to be a hybrid of true biological neurons and their computational abstractions known as multilayer perceptrons.<p/>



<h3>Anatomy of The Neuron</h3><p/>
 
A neuron contains many input channels that deliver input signals from other neurons. Those channels are called <b>dendrites</b>. 
When a neuron is being stimulated by activity coming from dendrites, it wakes up and checks whether the incoming total stimulation exceeds the threshold
required for outbound stimulus. When that is the case, the neuron then forwards the signal through a tube that is called <b>axon</b>.
So a neuron has a multitude of dendrites for inbound signal traffic and one axon for outbound signal traffic. Axon is a broadcast object.
It gets an input signal from only one neuron and broadcasts the signal to all dendrites that it is connected to.
Therefore neurons are not directly connected to each other but rather through bridges:<p/>

<b>Neuron -> Axon -> Dendrites -> Neurons</b><p/>

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/400px-Neuron_Hand-tuned.svg.png" style="width:100%;max-width:350px"/><p/>

Since no neuron is useful if it is isolated from others, we'll modify neuron's constructor in a fashion that it takes in all its input neurons and
generates corresponding dendrites when instantiated.<p/>

<textarea style="width:100%;height:750px">

Neuron.new = function(inputNeurons) {
	var newNeuron = {
		dendrites: [],
		dendriteValues: [],
		axon: Axon.new(),
		getAxon: function() {
			return this.axon;
		},
		addInboundDendrite: function(newDendrite) {
			this.dendrites.push(newDendrite);
		}
	};
	for (var i = 0; i < inputNeurons.length; i++) {
		var inputNeuron = inputNeurons[i];
		var axon = inputNeuron.getAxon();
		var dendrite = Dendrite.new(newNeuron);
		axon.addOutboundDendrite(dendrite);
		newNeuron.addInboundDendrite(dendrite);
	}
	return newNeuron;
}
</textarea> <p/>

In our model, it is the dendrites that will contain the "wisdom" of the neural network. The dendrites will contain a weight
value that simulates the signal strength of biological neurons. The purpose of a neural network is to learn correlations between
input data and their observed result. The correlation is stored in neuron's dendrites and it is being further tuned toward
the optimum each time the neuron is fed with a new data sample. When a dendrite is created, it will have a random initial weight between 0 and 1. 
A dendrite must also have a reference to the host neuron so it can inform the neuron when it's being invoked by its axon. Axon invokes a dendrite
by calling its fire function. A dendrite can be fired only if it is loaded. And it cannot be fired twice without being reloaded in between. Only neuron can reload its dendrites.
Neuron only reloads its dendrites once it has invoked its axon. This is a safety measure that prevents dendrites from going
crazy and "voting" many times.

<p/>

<textarea style="width:100%;height:750px">

var Dendrite.new = function(neuron) {
	return {
		id: Dendrite.generateId(),
		neuron: neuron,
		weight: Math.random(), // random between 0 and 1
		loaded: true,
		fire: function(inboundValue) {
			if (!this.loaded) {
				return;
			}
			this.loaded = false;
			var outboundValue = inboundValue * this.weight;
			this.neuron.addValue(outboundValue);
		},
		reload: function() {
			this.loaded = true;
		}
	}
}
</textarea><p/>

Please note that Dendrite is now calling neuron's method <b>addValue</b> that I didn't define yet.
Let's implement that function for Neuron class. It's purpose is to add a new weighed value to Neuron dripping in from its many neurons.
Neuron will keep track of these droplets joining in and when all dendrite channels have spitted out their values Neuron will
sum up those values and invoke its outbound signal system, the axon:<p/>

<textarea style="width:100%;height:750px">

	//new instance methods for Neuron...
	..
	addValue: function(newIncomingDendriteValue) {
		this.values.push(newIncomingDendriteValue);
		//check if all dendrites have given their value
		if (this.values.length != this.dendrites.length) {
			return;
		}
		var sumValue = this.sumDendriteValues();
		this.axon.fire(sumValue);
		this.reloadDendrites();
		this.dendriteValues = [];		
	},
	
	sumDendriteValues: function() {
		var totalValue = [];
		for (var i = 0; i < this.dendriteValues.length; i++) {
			var value = this.dendriteValues[i];
			totalValue += value;
		}
		return totalValue;
	},

	reloadDendrites: function() {
		for (var i = 0; i < this.dendrites.length; i++)  {
			var dendrite = this.dendrites[i];
			dendrite.reload();
		}
	}
	..

</textarea><p/>

Neuron's new instance methods described above will wake up neuron every time a dendrite pukes in its content. 
Neuron checks whether all dendrites have given their value. If so then those values are summed up and passed
over to the axon. After that all dendritic values are cleaned up and dendrites reloaded so that they can fire again.

<h3>To Be Continued...</h3>
                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul style="display:none" class="list-inline text-center">
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
		    <p class="copyright text-muted">View this article on <a href="https://github.com/develprr/oppikone-blog/commits/master/object-oriented-neural-network-in-javascript.html">GitHub!</a></p>
                    <p class="copyright text-muted">Copyright &copy; Oppikone 2016</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

</body>

</html>